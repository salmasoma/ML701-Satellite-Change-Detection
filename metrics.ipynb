{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "num_class = 37\n",
    "IMAGE_FORMAT = '.png'\n",
    "INFER_DIR = './second_dataset/pred_new/im2_rgb/'\n",
    "LABEL_DIR = './second_dataset/test/label2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_hist(a, b, n):\n",
    "    k = (a >= 0) & (a < n)\n",
    "    return np.bincount(n * a[k].astype(int) + b[k], minlength=n ** 2).reshape(n, n)\n",
    "\n",
    "\n",
    "def get_hist(image, label):\n",
    "    hist = np.zeros((num_class, num_class))\n",
    "    hist += fast_hist(image.flatten(), label.flatten(), num_class)\n",
    "    return hist\n",
    "\n",
    "\n",
    "def cal_kappa(hist):\n",
    "    if hist.sum() == 0:\n",
    "        po = 0\n",
    "        pe = 1\n",
    "        kappa = 0\n",
    "    else:\n",
    "        print(\"here\")\n",
    "        po = np.diag(hist).sum() / hist.sum()\n",
    "        pe = np.matmul(hist.sum(1), hist.sum(0).T) / hist.sum() ** 2\n",
    "        if pe == 1:\n",
    "            kappa = 0\n",
    "        else:\n",
    "            kappa = (po - pe) / (1 - pe)\n",
    "    return kappa\n",
    "\n",
    "\n",
    "def Eval():\n",
    "    name_list = sorted(os.listdir(INFER_DIR))\n",
    "    hist = np.zeros((num_class, num_class))\n",
    "    for idx in range(len(name_list)):\n",
    "        name = name_list[idx].split('.')[0]\n",
    "        infer_file = INFER_DIR + '/' + str(name) + IMAGE_FORMAT\n",
    "        label_file = LABEL_DIR + '/' + str(name) + IMAGE_FORMAT\n",
    "        infer = Image.open(infer_file)\n",
    "        label = Image.open(label_file)\n",
    "        infer_array = np.array(infer)\n",
    "        label_array = np.array(label)\n",
    "        hist += get_hist(infer_array, label_array)\n",
    "\n",
    "    print(\"Label distribution:\", np.unique(label_array, return_counts=True))\n",
    "\n",
    "    hist_fg = hist[1:, 1:]\n",
    "    c2hist = np.zeros((2, 2))\n",
    "    c2hist[0][0] = hist[0][0]\n",
    "    c2hist[0][1] = hist.sum(1)[0] - hist[0][0]\n",
    "    c2hist[1][0] = hist.sum(0)[0] - hist[0][0]\n",
    "    c2hist[1][1] = hist_fg.sum()\n",
    "    hist_n0 = hist.copy()\n",
    "    hist_n0[0][0] = 0\n",
    "    \n",
    "    kappa_n0 = cal_kappa(hist_n0)\n",
    "    iu = np.diag(c2hist) / (c2hist.sum(1) + c2hist.sum(0) - np.diag(c2hist))\n",
    "    IoU_fg = iu[1]\n",
    "    IoU_mean = (iu[0] + iu[1]) / 2\n",
    "    print('Kappa = %.5f' % kappa_n0)\n",
    "    print('IoU = %.5f' % IoU_fg)\n",
    "    Sek = (kappa_n0 * math.exp(IoU_fg)) / math.e\n",
    "\n",
    "    print('Mean IoU = %.5f' % IoU_mean)\n",
    "    print('Sek = %.5f' % Sek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: (array([  0, 128, 255], dtype=uint8), array([167644, 201896, 416892]))\n",
      "here\n",
      "Kappa = 0.00000\n",
      "IoU = 1.00000\n",
      "Mean IoU = 1.00000\n",
      "Sek = 0.00000\n"
     ]
    }
   ],
   "source": [
    "Eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = Image.open('./second_dataset/pred_new/im2_rgb/02161.png')\n",
    "\n",
    "#show the image\n",
    "infer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 4 4 4]\n",
      " [0 0 0 ... 4 4 4]\n",
      " [0 0 0 ... 4 4 4]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "infer = Image.open('./second_dataset/pred_new/im2_rgb/02161.png')\n",
    "infer_array = np.array(infer)\n",
    "\n",
    "def rgb_to_class(image, colormap):\n",
    "    # Convert colormap to a NumPy array for efficient processing\n",
    "    colormap = np.array(colormap)\n",
    "    class_map = np.zeros((image.shape[0], image.shape[1]), dtype=int)\n",
    "\n",
    "    # Iterate over the colormap and assign class labels\n",
    "    for class_idx, color in enumerate(colormap):\n",
    "        matches = np.all(image == color, axis=-1)\n",
    "        class_map[matches] = class_idx\n",
    "\n",
    "    return class_map\n",
    "\n",
    "# Example usage\n",
    "ST_COLORMAP = [[255, 255, 255], [0, 0, 255], [128, 128, 128], [0, 128, 0], [0, 255, 0], [128, 0, 0], [255, 0, 0]]\n",
    "class_array = rgb_to_class(infer_array, ST_COLORMAP)\n",
    "print(class_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "255\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "infer_array = np.array(infer)\n",
    "print(infer_array[0][511][0])\n",
    "print(infer_array[0][511][1])\n",
    "print(infer_array[0][511][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "Kappa = 0.23811\n",
      "IoU = 0.40299\n",
      "Mean IoU = 0.62667\n",
      "Sek = 0.13107\n"
     ]
    }
   ],
   "source": [
    "name_list = sorted(os.listdir(INFER_DIR))\n",
    "hist = np.zeros((num_class, num_class))\n",
    "infer = Image.open('./second_dataset/pred_new/im2_rgb/02161.png')\n",
    "label = Image.open('./second_dataset/test/label2/02161.png')\n",
    "infer_array = np.array(infer)\n",
    "label_array = np.array(label)\n",
    "infer_array = rgb_to_class(infer_array, ST_COLORMAP)\n",
    "label_array = rgb_to_class(label_array, ST_COLORMAP)\n",
    "hist += get_hist(infer_array, label_array)\n",
    "\n",
    "\n",
    "\n",
    "hist_fg = hist[1:, 1:]\n",
    "c2hist = np.zeros((2, 2))\n",
    "c2hist[0][0] = hist[0][0]\n",
    "c2hist[0][1] = hist.sum(1)[0] - hist[0][0]\n",
    "c2hist[1][0] = hist.sum(0)[0] - hist[0][0]\n",
    "c2hist[1][1] = hist_fg.sum()\n",
    "hist_n0 = hist.copy()\n",
    "hist_n0[0][0] = 0\n",
    "\n",
    "kappa_n0 = cal_kappa(hist_n0)\n",
    "iu = np.diag(c2hist) / (c2hist.sum(1) + c2hist.sum(0) - np.diag(c2hist))\n",
    "IoU_fg = iu[1]\n",
    "IoU_mean = (iu[0] + iu[1]) / 2\n",
    "print('Kappa = %.5f' % kappa_n0)\n",
    "print('IoU = %.5f' % IoU_fg)\n",
    "Sek = (kappa_n0 * math.exp(IoU_fg)) / math.e\n",
    "\n",
    "print('Mean IoU = %.5f' % IoU_mean)\n",
    "print('Sek = %.5f' % Sek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "0.0 ////// 0.0\n"
     ]
    }
   ],
   "source": [
    "kappa_n0 = cal_kappa(hist_n0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kappa_n0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32471139.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_n0.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa = 0.00000\n",
      "IoU = 1.00000\n",
      "Mean IoU = 1.00000\n",
      "Sek = 0.00000\n"
     ]
    }
   ],
   "source": [
    "Eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Metrics for segmentation.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    \"\"\"Tracking mean metrics\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels):\n",
    "        \"\"\"Creates an new `Metrics` instance.\n",
    "\n",
    "        Args:\n",
    "          labels: the labels for all classes.\n",
    "        \"\"\"\n",
    "\n",
    "        self.labels = labels\n",
    "\n",
    "        self.tn = 0\n",
    "        self.fn = 0\n",
    "        self.fp = 0\n",
    "        self.tp = 0\n",
    "\n",
    "    def add(self, actual, predicted):\n",
    "        \"\"\"Adds an observation to the tracker.\n",
    "\n",
    "        Args:\n",
    "          actual: the ground truth labels.\n",
    "          predicted: the predicted labels.\n",
    "        \"\"\"\n",
    "        masks = torch.argmax(predicted, 0)\n",
    "        # confusion = masks.view(-1).float() / actual.view(-1).float()\n",
    "        ground_truths = actual\n",
    "        pred = masks\n",
    "        self.tn += np.array(torch.sum((ground_truths == 0) & (pred == 0)).cpu())\n",
    "        self.fn += np.array(torch.sum((ground_truths == 1) & (pred == 0)).cpu())\n",
    "        self.fp += np.array(torch.sum((ground_truths == 0) & (pred == 1)).cpu())\n",
    "        self.tp += np.array(torch.sum((ground_truths == 1) & (pred == 1)).cpu())\n",
    "        # a = self.tp / (self.tp + self.fp)\n",
    "        # a = pred\n",
    "\n",
    "        # self.tn += torch.sum(torch.isnan(confusion)).item()\n",
    "        # self.fn += torch.sum(confusion == float(\"inf\")).item()\n",
    "        # self.fp += torch.sum(confusion == 0).item()\n",
    "        # self.tp += torch.sum(confusion == 1).item()\n",
    "\n",
    "    def get_precision(self):\n",
    "\n",
    "        return self.tp / (self.tp + self.fp)\n",
    "\n",
    "    def get_recall(self):\n",
    "\n",
    "        return self.tp / (self.tp + self.fn)\n",
    "\n",
    "    def get_f_score(self):\n",
    "\n",
    "        pr = 2 *(self.tp / (self.tp + self.fp)) * (self.tp / (self.tp + self.fn))\n",
    "        p_r = (self.tp / (self.tp + self.fp)) + (self.tp / (self.tp + self.fn))\n",
    "        return pr / p_r\n",
    "\n",
    "    def get_oa(self):\n",
    "        \n",
    "        t_pn = self.tp + self.tn\n",
    "        t_tpn = self.tp + self.tn + self.fp + self.fn\n",
    "        return t_pn / t_tpn\n",
    "\n",
    "    def kappa(self):\n",
    "\n",
    "        t_pn = self.tp + self.tn\n",
    "        t_tpn = self.tp + self.tn + self.fp + self.fn\n",
    "        po = t_pn / t_tpn\n",
    "        pe_1 = (self.tn + self.fn)*(self.tn + self.fp) + (self.fp + self.tp)*(self.fn + self.tp)\n",
    "        pe_2 = t_tpn * t_tpn\n",
    "        pe = pe_1 / pe_2\n",
    "        ka = (po - pe) / (1 - pe)\n",
    "        return ka\n",
    "\n",
    "    def get_miou(self):\n",
    "        \"\"\"Retrieves the mean Intersection over Union score.\n",
    "\n",
    "        Returns:\n",
    "          The mean Intersection over Union score for all observations seen so far.\n",
    "        \"\"\"\n",
    "        return np.nanmean([self.tn / (self.tn + self.fn + self.fp), self.tp / (self.tp + self.fn + self.fp)])\n",
    "\n",
    "    def get_fg_iou(self):\n",
    "        \"\"\"Retrieves the foreground Intersection over Union score.\n",
    "\n",
    "        Returns:\n",
    "          The foreground Intersection over Union score for all observations seen so far.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            iou = self.tp / (self.tp + self.fn + self.fp)\n",
    "        except ZeroDivisionError:\n",
    "            iou = float(\"Inf\")\n",
    "\n",
    "        return iou\n",
    "\n",
    "    def get_mcc(self):\n",
    "        \"\"\"Retrieves the Matthew's Coefficient Correlation score.\n",
    "\n",
    "        Returns:\n",
    "          The Matthew's Coefficient Correlation score for all observations seen so far.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            mcc = (self.tp * self.tn - self.fp * self.fn) / math.sqrt(\n",
    "                (self.tp + self.fp) * (self.tp + self.fn) * (self.tn + self.fp) * (self.tn + self.fn)\n",
    "            )\n",
    "        except ZeroDivisionError:\n",
    "            mcc = float(\"Inf\")\n",
    "\n",
    "        return mcc\n",
    "\n",
    "\n",
    "# Todo:\n",
    "# - Rewrite mIoU to handle N classes (and not only binary SemSeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
